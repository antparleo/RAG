{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcec673",
   "metadata": {},
   "source": [
    "# Chroma Database Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c4587",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df9b888",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://gsrm.ivi.org:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://gsrm.ivi.org:8888/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "import langchain_community\n",
    "import langchain_text_splitters\n",
    "from langchain_community.document_loaders import PyPDFLoader, pdf\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import pprint\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import uuid\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import unicodedata\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import uuid\n",
    "# from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "import pickle as pkl\n",
    "import requests\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4ea84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api_google.txt') as f:\n",
    "    \n",
    "    api_key = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9cd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = api_key['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d295dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\",temperature=0,max_output_tokens=1024) # gemma-3-27b-it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a4892",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7558ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"info_articles_main.pkl\",\"rb\") as f:\n",
    "    info_articles_main = pkl.load(f)\n",
    "with open(\"info_articles_ref_final.pkl\",\"rb\") as f:\n",
    "    info_articles_ref = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b641d8",
   "metadata": {},
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef787c",
   "metadata": {},
   "source": [
    "### Split the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e689c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=1500/10,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]  # smart splitting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fa4e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_articles_final = info_articles_main + info_articles_ref\n",
    "len(info_articles_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d2f19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_splitted = []\n",
    "\n",
    "for j in info_articles_final:\n",
    "\n",
    "    for key, value in j.items():\n",
    "    \n",
    "        if key in ['Abstract', 'Introduction', 'Methods', 'Results', 'Discussion', 'Conclusion',] and value:\n",
    "\n",
    "            if len(value) > 1700:\n",
    "                chunks = splitter.split_text(value)\n",
    "\n",
    "                for i, c in enumerate(chunks):\n",
    "\n",
    "                    info_splitted.append(\n",
    "                        {\n",
    "                            \"chunk_index\":i,\n",
    "                            \"content\": j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")+\", DOI:\"+j.get(\"DOI\")+\":\\n \"+c,\n",
    "                            \"parent\":key,\n",
    "                            \"split\":True,\n",
    "                            \"DOI\":j.get(\"DOI\"),\n",
    "                            \"Reference\": j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")\n",
    "                        }\n",
    "                    )\n",
    "            else:\n",
    "\n",
    "                info_splitted.append(\n",
    "                        {\n",
    "                            \"chunk_index\":0,\n",
    "                            \"content\":j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")+\", DOI:\"+j.get(\"DOI\")+\":\\n \"+value,\n",
    "                            \"parent\":key,\n",
    "                            \"split\":False,\n",
    "                            \"DOI\":j.get(\"DOI\"),\n",
    "                            \"Reference\": j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")\n",
    "                        }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0809f73",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065057d",
   "metadata": {},
   "source": [
    "We chose this embedding according to leaderboard of HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bae4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_function2 = HuggingFaceEmbeddings(model_name=\"avsolatorio/GIST-small-Embedding-v0\") # model_kwargs={'device': 'cuda'}\n",
    "# embedding_function2 = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-s\")\n",
    "embedding_function2 = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")  #intfloat/e5-small-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786e097",
   "metadata": {},
   "source": [
    "## Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "961b72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepare documents, metadata, and IDs\n",
    "texts = [chunk[\"content\"] for chunk in info_splitted]\n",
    "metadatas = [{\"parent\": chunk[\"parent\"], \"chunk_index\": chunk[\"chunk_index\"],\"DOI\": chunk[\"DOI\"], \"Reference\": chunk[\"Reference\"]} for chunk in info_splitted]\n",
    "ids = [str(uuid.uuid1()) for _ in metadatas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b79161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embedding_function2,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    collection_name=\"ReproRAG\",\n",
    "    persist_directory=\"./chromaRepro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cb121",
   "metadata": {},
   "source": [
    "We check that the search works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b92eabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'chunk_index': 2, 'parent': 'Discussion', 'Reference': 'P. Sebastian-Leon et al.,2018', 'DOI': 'https://doi.org/10.1093/humrep/dey023'}, page_content='P. Sebastian-Leon et al.,2018, DOI:https://doi.org/10.1093/humrep/dey023:\\n ., 2008), or have good predictive value for both, such as Altmäe2010 who designed the study for unexplained infertility versus fertile controls (Altmäe et al., 2010). On the other hand, in the pathological prediction model, most of the signatures designed to distinguish between fertility and infertility improved their accuracy using correction by transcriptomic clusters instead of LH criteria ( Koot et al.,2 0 1 6). Based on thesefindings, we conclude that endometrial timing is a confounding variable that has been covering up the molecular disruption effect and that the improvement of the prediction due to transcriptomic correction reveals that the transcriptomic cluster provides better criteria than LH for timing effect removal. In addition, these results reinforce previous suggestions made by us related to using transcriptomics as stratification criteria instead of postLH day criteria in endometrium ( Díaz-Gimeno et al., 2017). Figure 1Signatures meaning in terms of displacement or disruption. Prediction model performance for selected signatures compared with random results. Each black point represents a signature accuracy (Y axis) related to its gene size (X axis). Grey shadows represent the mean and 95% CI for random signature models. (A) Displacement model. The accuracy increases with gene size and arrives at a saturation point (size= 500 genes) from which the accuracy then decreases'),\n",
       " Document(metadata={'DOI': 'https://doi.org/10.1093/humrep/dey023', 'chunk_index': 1, 'parent': 'Results', 'Reference': 'P. Sebastian-Leon et al.,2018'}, page_content='P. Sebastian-Leon et al.,2018, DOI:https://doi.org/10.1093/humrep/dey023:\\n . A detailed comparison is shown in Supplementary Fig. S3. What molecular causes of RIF are predicting the signatures? The predictive ability of signatures in detecting WOI timing showed that all of them distinguished this endometrial phenotype with very good accuracy. The minimum accuracy was 0.85 for the Koot signature (Fig. 1A). Eleven signatures (Kao, Riesewijk, Borthwick, Mirkin, Punyadeera, Talbi, Carrascosa, Diaz-Gimeno, Bhagwat, Bersinger and Altmäe2017) gave higher values for predicting timing than expected by chance, while only one (Koot) was lower than expected by chance (Fig. 1A). The predictive capability for disrupted RIF detection was lower in general and less than expected by chance; only Koot and Altmäe2010 showed a predictive value higher than expected by chance (Fig. 1B). The ability to predict both RIF causes for each signature showed three predictive behaviours (Fig.2A): signatures with a good predictive value in disruption but a worse predictive value in displacement (Koot); a group that had good prediction power for displacement and worse for disruption (represented by Kao, Mirkin Diaz-Gimeno, Bersinger, Borthwick, Bhagwat, Riesewijk, Carrascosa, Talbi and Altmäe2017); and finally, a group that had good predictive value for both causes, represented by the Altmäe2010, Punyadeera, Carson, and Ponnampalam signatures'),\n",
       " Document(metadata={'chunk_index': 12, 'Reference': 'P. Diaz-Gimeno et al.,2022', 'parent': 'Methods', 'DOI': 'https://doi.org/10.1093/humrep/deab262'}, page_content='P. Diaz-Gimeno et al.,2022, DOI:https://doi.org/10.1093/humrep/deab262:\\n . S3A). Prediction performance of each published endometrial signature (Dı ́azGimeno et al.,2 0 1 1; Hamamah, 2016; Enciso et al.,2 0 1 8), top predictive genes from endometrial datasets (Top50), and the new signature proposed in this study (TED) were also calculated separately for each dataset (Supplementary Fig. S3B). Then, the same approach was applied selecting signatures of different size from genes ordered by informativity score and increasing the gene signature size for each dataset from best to worst informativity score, to obtain predictive behaviour of genes with better informativity score values, and from worst to best informativity score to obtain predictive behaviour of genes with worst informativity score values (Supplementary Fig. S3C). Finally, more than 288 Diaz-Gimeno et al. Downloaded from https://academic.oup.com/humrep/article/37/2/284/6454792 by guest on 08 February 2023  ......................................... ................................................... ........... . ..................................... ................................ 200 000 prediction models were run in Weka. All plots were generated using ggplot2 package in R (Wickham, 2016).'),\n",
       " Document(metadata={'chunk_index': 3, 'parent': 'Introduction', 'Reference': 'P. Diaz-Gimeno et al.,2022', 'DOI': 'https://doi.org/10.1093/humrep/deab262'}, page_content='P. Diaz-Gimeno et al.,2022, DOI:https://doi.org/10.1093/humrep/deab262:\\n ., 2010; Su et al.,2 0 1 4). In line with this, algorithms applied to gene expression data from known samples (e.g. known menstrual cycle phase at time of endometrial biopsy) can enable predictions for unknown samples with parameters including accuracy (ACC), sensitivity and specificity, as well as an error estimation throughout a cross-validation process (Kohavi, 1995). Prediction models and signature discovery originate through a learning process in a reference set of samples called a training set for signature discovery and robustness occurs in an independent set of samples called a test set (Dı ́az-Gimeno et al., 2017). These next-generation TED tools assess different gene combinations and use different methodologies and platforms to measure gene expression. However, it remains unclear what characteristics determine the capacity of different signatures to predict endometrial progression and why there is a large discrepancy in gene content between these signatures ( Sebastian-Leon et al. , 2018). We therefore used a variety of artificial intelligence algorithms to compare the predictive performance of published gene panels and other signatures created randomly for understanding signatures behaviour related to human menstrual cycle progression. We also applied the algorithms to a novel set of genes, allowing development of a new prediction model employing an optimal gene signature for endometrial dating and analysed us ing a targeted next-generation sequencing approach.'),\n",
       " Document(metadata={'chunk_index': 6, 'parent': 'Methods', 'DOI': 'https://doi.org/10.1016/j.fertnstert.2024.03.015', 'Reference': 'Patricia Diaz-Gimeno et al.,2024'}, page_content='Patricia Diaz-Gimeno et al.,2024, DOI:https://doi.org/10.1016/j.fertnstert.2024.03.015:\\n EFR signature capability as a biomarker of endometrial disruption\\nTo estimate the prediction capability of the EFR signature to distinguish poor and good endometrial prognosis profiles, we implemented predictive models on the basis of the Support Vector Machine algorithm. Using a stratified fivefold crossvalidation process (repeated 100 times), the accuracy, sensitivity, and specificity were estimated. The range of values obtained across the 100 iterations was presented as a boxplot using ggplot2.\\nStatistical analysis\\nRates for reproductive outcomes (ie, pregnancy rate [PR], cumulative pregnancy rate [CPR], live birth rate [LBR], biochemical miscarriage rate [BMR], and clinical miscarriage rate [CMR]) were calculated as de fined in the Supplemental Methods. Descriptive statistics were used for transcriptomic and clinical characteristics of patients to compare prognosis or WOI displacement groups. Continuous variables were presented as an overall mean /C6 standard deviation whereas discrete variables were presented as counts and percentages. Groups were compared using the Wilcoxon rank-sum test for continuous variables and Fisher’s exact test for discrete variables. All statistical analyses were conducted in R. All graphical results were generated with ggplot2.\\nGene expression validation by quantitative realtime polymerase chain reaction'),\n",
       " Document(metadata={'DOI': 'https://doi.org/10.1016/j.fertnstert.2024.03.015', 'Reference': 'Patricia Diaz-Gimeno et al.,2024', 'chunk_index': 2, 'parent': 'Methods'}, page_content='Patricia Diaz-Gimeno et al.,2024, DOI:https://doi.org/10.1016/j.fertnstert.2024.03.015:\\n Study design\\nFirst, a custom RNA-seq gene panel (the endometrial failure risk [EFR] panel) comprising 404 biomarkers of endometrial luteal phase timing and/or potential disruption was designed and employed to determine the risk of endometrial failure among 217 IVF patients (Supplemental Fig. 1, step 1 available online). The endometrial timing-corrected expression of the EFR panel was used to study the differential expression associated with endometrial disruption together with clinical characteristics of IVF patients to stratify the population as having poor or good endometrial prognoses, according to a semi-supervised learning process (Supplemental Fig. 1, step 2). The distinct transcriptomic patterns of each prognosis group were associated with the differences in reproductive outcomes of SET after biopsy collection, and the differentially expressed gene signature was proposed as a biomarker of endometrial disruption (Supplemental Fig. 1, step 3). Finally, the gene expression signature was used to supervise machine learning algorithms to evaluate the biomarker capacity of this signature to distinguish endometrial competence. The predictive performance of the models was assessed through the accuracy, sensibility, and specificity over 100 iterations of fivefold strati fied cross-validation ( Supplemental Fig. 1 , step 4).\\nConstructing the EFR gene panel'),\n",
       " Document(metadata={'Reference': 'Patricia Diaz-Gimeno et al.,2024', 'DOI': 'https://doi.org/10.1016/j.fertnstert.2024.03.015', 'parent': 'Abstract', 'chunk_index': 1}, page_content='Patricia Diaz-Gimeno et al.,2024, DOI:https://doi.org/10.1016/j.fertnstert.2024.03.015:\\n .6% vs. 79.6%), live birth (25.6% vs. 77.6%), clinical miscarriage (22.2% vs. 2.6%), and biochemical miscarriage (20.4% vs. 0%). The relative risk of endometrial failure for patients predicted as a poor endometrial prognosis was 3.3 times higher than those with a good prognosis. The differences in gene expression between both profiles were proposed as a biomarker, coined the endometrial failure risk (EFR) signature. Poor prognosis profiles were characterized by 59 upregulated and 63 downregulated genes mainly involved in regulation (17.0%), metabolism (8.4%), immune response, and inflammation (7.8%). This EFR signature had a median accuracy of 0.92 (min1⁄40.88, max1⁄40.94), median sensitivity of 0.96 (min1⁄40.91, max 1⁄4 0.98), and median specificity of 0.84 (min 1⁄4 0.77, max 1⁄4 0.88), positioning itself as a promising biomarker for endometrial evaluation. Conclusion(s): The EFR signature revealed a novel endometrial disruption, independent of endometrial luteal phase timing, present in 73.7% of patients. This EFR signature stratified patients into 2 significantly distinct and clinically relevant prognosis profiles providing opportunities for personalized therapy. Nevertheless, further validations are needed before implementing this gene signature as an artificial intelligence (AI)-based tool to reduce the risk of patients experiencing endometrial failure. (Fertil Steril /C2102024;-:-- -. /C2112024 by American Society for Reproductive Medicine.)'),\n",
       " Document(metadata={'chunk_index': 1, 'DOI': 'https://doi.org/10.1093/humupd/dmt048', 'parent': 'Discussion', 'Reference': 'Signe Altmäe et al.,2013'}, page_content='Signe Altmäe et al.,2013, DOI:https://doi.org/10.1093/humupd/dmt048:\\n Diaz-Gimeno\\net al.\\n, 2013\\n). Furthermore, pathological states of the endometrium must be considered, including the impact of structural (fibroids) or immune (endometriosis) alterations. Together with concurrent medication or exposures to environmental toxins as well as genetic susceptibility, all of these factors can alter ‘omics’ outcomes (\\nHorcajadas\\net al.\\n, 2007\\n;\\nSavaris and Giudice, 2009\\n). The importance of study design has previously been addressed in several reviews (\\nWhite and Salamonsen, 2005\\n;\\nHorcajadas\\net al.\\n, 2007\\n;\\nSavaris and Giudice, 2009\\n;\\nBellver\\net al.\\n, 2012\\n;\\nRuiz-Alonso\\net al.\\n, 2012\\n;\\nEdgell\\net al.\\n, 2013\\n) but we hereby briefly summarize the critical points.\\nFirst and foremost, researchers should be precise and consistent in defining the phenotype of the study population. Heterogeneity resulting from misclassifying participants decreases both sensitivity and power. The phenotypic heterogeneity across studies often makes it difficult to generalize study findings and replicate the results (\\nWu\\net al.\\n, 2013\\n). While a clear phenotype definition could potentially reduce sample size, it will increase biological homogeneity and thus increase the statistical power (\\nGracie\\net al.\\n, 2011'),\n",
       " Document(metadata={'DOI': 'https://doi.org/10.1093/humrep/deaf156', 'parent': 'Introduction', 'Reference': 'Josefa Maria Sanchez-Reyes et al.,2025', 'chunk_index': 3}, page_content='Josefa Maria Sanchez-Reyes et al.,2025, DOI:https://doi.org/10.1093/humrep/deaf156:\\n . Our new  prognostic stratification elucidates the molecular heterogeneity  of the endometrial disruptions in the mid-secretory phase, inde - pendent of endometrial timing.'),\n",
       " Document(metadata={'parent': 'Results', 'Reference': 'Maria Ruiz-Alonso et al.,2021', 'chunk_index': 7, 'DOI': 'https://doi.org/10.1093/hropen/hoab011'}, page_content='Maria Ruiz-Alonso et al.,2021, DOI:https://doi.org/10.1093/hropen/hoab011:\\n when biopsies were obtained and statistical analysis applied to the results, among other\\nfactors. In sum, all the studies aiming to identify the physiological transcriptomic profile\\nacross the menstrual cycle reached the same conclusion: it is possible to accurately\\ncatalogue endometria at different stages based on their transcriptomic signatures,\\nspecifically the identification of the WOI (see above: ‘A decade of basic research leading\\nto the transcriptomic characterisation of the human endometrium’). Further, the\\nmachine-learning predictors used to relate these gene signatures with clinical diagnosis\\nhave differed. As an example, in our test, the core of the receptivity diagnosis is powered\\nby 134 ERA genes, while the remaining genes target putative WOI displacements.\\nSince the publication of our seminal paper identifying the transcriptomic signature of\\nendometrial receptivity (\\nDíaz-Gimeno\\net\\nal.\\n, 2011\\n), six different companies have launched commercial endometrial\\ntranscriptomic tests under different acronyms with different evidence. WinTest from INSERM\\n(\\nwww.inserm.fr/en\\n) is based on 11 genes\\ndetected using RT-qPCR, with four publications demonstrating transcriptomic and clinical\\nconsistency (\\nHaouzi\\net al.\\n,\\n2009\\n;\\nHaouzi, 2015\\n;\\nBissonnette\\net al.\\n, 2016\\n;\\nHaouzi\\net al.\\n, 2021\\n). ERPeak\\nfrom Cooper Surgical (USA) (\\nhttps://fertility.coopersurgical.com/genomics/erpeak-endometrial-receptivity-test/\\n)\\nand ERMap from IGLS (Spain) (')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"Is there a signature to predict endometrial disruption?\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c90458",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceba79f",
   "metadata": {},
   "source": [
    "### Agents for questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9c2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(llm, prompt):\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c74c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_generation_prompt = \"\"\"\n",
    "You are given a piece of scientific text (context).\n",
    "Your task is to generate ONE question and ONE answer from it.\n",
    "\n",
    "Guidelines for the question:\n",
    "- It must be factual and answerable using the context only.\n",
    "- Phrase it naturally, as if a researcher typed it into a search engine.\n",
    "- Do NOT mention \"context\", \"passage\", or \"according to the text\".\n",
    "- The question should be specific and concise.\n",
    "\n",
    "Guidelines for the answer:\n",
    "- The answer must be a short, factual statement directly supported by the context.\n",
    "- Do not add explanations, speculation, or references to the text.\n",
    "\n",
    "Formatting rules (strict):\n",
    "Output:::\n",
    "Question: <your question here>\n",
    "Answer: <your answer here>\n",
    "\n",
    "Now here is the context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Output:::\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787c51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_splitted_evaluation = [d for d in info_splitted if d['parent'] in ['Abstract','Introduction','Results','Conclusion','Discussion','Methods']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69dd44e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_index': 1, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n . The search identified experiments involving human endometrial transcriptomic case versus control raw data related to uterine pathologies and implantation alterations. The keywords employed in the search included endometriosis, endometrial adenocarcinoma (ADC), recurrent implantation failure (RIF), and recurrent pregnancy loss (RPL), among others (Supplemental Table 1A, available online, for a full list of search terms). No restrictions were placed on publication date or language. Uterine leiomyoma, adenomyosis, and uterine leiomyosarcoma data were not included due to a lack of suitable studies meeting our criteria. For each sample cohort belonging to the same individual study, 39 variables were evaluated (see Supplemental Table 1B), including clinical characteristics of the participants (e.g., age and body mass index), experimental design (e.g., endometrial biopsy preprocessing procedure and transcriptomic platform), and additional study information (e.g', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 0, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n MATERIALS AND METHODS This is a retrospective study integrating case and control data from multiple cohorts with endometrium gene expression in women with uterine disorders. The raw gene expression data and patient meta-data were downloaded from the National Center for Biotechnology Information (NCBI) functional genomics data repository Gene Expression Omnibus (GEO), where data are made available for the scientific community. Following GEO policies, in this repository patient data are anonymized and encrypted, and no additional institutional review board is required for downloading . Study Search and Selection Systematic searches and reviews of individual studies were conducted between October 2016 and June 2017 at the NCBI functional genomics data repository GEO  according to preferred reporting items for systematic reviews and metaanalysis (PRISMA) guidelines', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 1, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n . The search identified experiments involving human endometrial transcriptomic case versus control raw data related to uterine pathologies and implantation alterations. The keywords employed in the search included endometriosis, endometrial adenocarcinoma (ADC), recurrent implantation failure (RIF), and recurrent pregnancy loss (RPL), among others (Supplemental Table 1A, available online, for a full list of search terms). No restrictions were placed on publication date or language. Uterine leiomyoma, adenomyosis, and uterine leiomyosarcoma data were not included due to a lack of suitable studies meeting our criteria. For each sample cohort belonging to the same individual study, 39 variables were evaluated (see Supplemental Table 1B), including clinical characteristics of the participants (e.g., age and body mass index), experimental design (e.g., endometrial biopsy preprocessing procedure and transcriptomic platform), and additional study information (e.g', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 2, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n .g., GEO identifier and associated publication). Thefinal inclusion criteria were that at least one uterine disorder was evaluated in the sample cohort study design, RNA was extracted directly from human endometrial biopsies (samples collected from eutopic endometrium in endometriosis patients), the sample size was greater than three for both case and control groups belonging to the same study, microarray or RNA sequencing data were obtained using Affymetrix, Illumina, or Agilent gene expression platforms, and raw gene expression data were made freely available to download from GEO. Individual Transcriptomic Analysis: Making Functional Results Comparable The same transcriptomic analysis procedure was applied independently to each of the selected individual data sets for making the functional results comparable to one another before being integrated through functional meta-analysis', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 3, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n . The individual transcriptomic analysis consisted of three consecutive steps run in R software  and applied separately to compare cases versus controls within samples from the same study to avoid variability among sample cohorts related to different uterine disorders. The same preprocessing of raw gene expression data, differential expression analysis, and functional enrichment analysis was performed in a sample cohort comparing cases versus controls ( Supplemental Fig. 1A , available online). The preprocessing step was performed using the affy v.1.52.0  R package for studies using Affymetrix platforms to measure gene expression and thelimma v.3.34.5 1262 VOL. 113 NO. 6 / JUNE 2020 ORIGINAL ARTICLE: GENETICS   R package for the remaining platforms. Normalization between samples was done using quantile normalization (limma R package) . Annotation from probe set to gene symbol was implemented with the biomaRt R package v.2.30.0', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 4, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n . Annotation from probe set to gene symbol was implemented with the biomaRt R package v.2.30.0 . Next, exploratory analyses were performed to detect outliers and batch effects. The effect of the cycle phase of endometrial biopsy collection on the data was removed using linear models (limma v.3.34.5) as previously described elsewhere  because the samples were collected throughout the menstrual cycle . This correction ensures that the functional alterations obtained are due to the uterine disorder instead of the different proportions of cell types (stromal, epithelial) and/or the distinct menstrual cycle stages in which the endometrial biopsy samples were obtained . Differential expression analyses were applied using the limma R package  and functional enrichment analyses were executed using the gene set enrichment analysis (GSEA) logistic model implemented in themdgsa R package . TheP values for each function were calculated and corrected for false discovery rate (FDR)', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 5, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n . TheP values for each function were calculated and corrected for false discovery rate (FDR) . Two functional databases were consulted: the Kyoto Encyclopedia of Genes and Genomes (KEGG)  (release 81.0/2017-1-1) and Gene Ontology (GO)  (Release 1.2/2017-03-31). Functional Integration A functional meta-analysis using mdgsa  and metafor , R packages  was applied for each gene function evaluated, integrating each function among the different patient cohorts belonging to the same disorder (see Supplemental Fig. 1A). This methodology robustly highlights the common alterations across a set of studies, thus discarding those alterations that are exclusive of each individual study’s characteristics . In addition, it increases the statistical power through the integration of a higher number of samples and overcomes the limitations of individual studies’ heterogeneity regarding their distinct clinical population characteristics and experimental procedures', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 6, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n . All integrations were performed under the DerSimonian and Laird  random effects model to account for individual study heterogeneity in the R environment . This model weighs the functional results of each study according to their inherent variability measured by the standard deviation (SD) of the logarithm of odds ratio (LOR) obtained in the GSEA analysis for each evaluated function. Consequently, studies with less variability are weighted more in the computation of thefinal meta-analysis results than those with high variability. Thus, meta-analysis highlights the most robust endometrial functions associated with each uterine disorder. A total of 6,390 functions (226 KEGG pathways, 4,405 GO biological processes (BP) terms, 1,093 GO molecular functions (MF) terms, and 666 GO cellular components (CC) terms) were evaluated through meta-analysis for each uterine disorder', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "{'chunk_index': 7, 'content': 'Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\\n .P values were corrected for multiple testing by FDR , and functions were considered statistically signi ficant in the meta-analysis when FDR<0.05. The P values, summary LOR, and 95% confidence interval (CI) were calculated for all functions evaluated in the metaanalysis. To ensure unbiased results, funnel plots were analyzed for each function evaluated in the meta-analysis. The standard error (SE) of the individual LOR for each integrated study was calculated as an accuracy measure of the study performance. The LOR represents the effect size of the function associated with each uterine disorder compared with controls. If study heterogeneity and publication bias did not affect the functional meta-analysis, the individual LOR of all the integrated studies will be inside the 95% CI area of the funnel plot .', 'parent': 'Methods', 'split': True, 'DOI': 'https://doi.org/10.1016/j.fertnstert.2020.01.025', 'Reference': 'Almudena Devesa-Peiro et al.,2020'}\n",
      "Almudena Devesa-Peiro et al.,2020, DOI:https://doi.org/10.1016/j.fertnstert.2020.01.025:\n",
      " MATERIALS AND METHODS This is a retrospective study integrating case and control data from multiple cohorts with endometrium gene expression in women with uterine disorders. The raw gene expression data and patient meta-data were downloaded from the National Center for Biotechnology Information (NCBI) functional genomics data repository Gene Expression Omnibus (GEO), where data are made available for the scientific community. Following GEO policies, in this repository patient data are anonymized and encrypted, and no additional institutional review board is required for downloading . Study Search and Selection Systematic searches and reviews of individual studies were conducted between October 2016 and June 2017 at the NCBI functional genomics data repository GEO  according to preferred reporting items for systematic reviews and metaanalysis (PRISMA) guidelines. The search identified experiments involving human endometrial transcriptomic case versus control raw data related to uterine pathologies and implantation alterations. The keywords employed in the search included endometriosis, endometrial adenocarcinoma (ADC), recurrent implantation failure (RIF), and recurrent pregnancy loss (RPL), among others (Supplemental Table 1A, available online, for a full list of search terms). No restrictions were placed on publication date or language. Uterine leiomyoma, adenomyosis, and uterine leiomyosarcoma data were not included due to a lack of suitable studies meeting our criteria. For each sample cohort belonging to the same individual study, 39 variables were evaluated (see Supplemental Table 1B), including clinical characteristics of the participants (e.g., age and body mass index), experimental design (e.g., endometrial biopsy preprocessing procedure and transcriptomic platform), and additional study information (e.g.g., GEO identifier and associated publication). Thefinal inclusion criteria were that at least one uterine disorder was evaluated in the sample cohort study design, RNA was extracted directly from human endometrial biopsies (samples collected from eutopic endometrium in endometriosis patients), the sample size was greater than three for both case and control groups belonging to the same study, microarray or RNA sequencing data were obtained using Affymetrix, Illumina, or Agilent gene expression platforms, and raw gene expression data were made freely available to download from GEO. Individual Transcriptomic Analysis: Making Functional Results Comparable The same transcriptomic analysis procedure was applied independently to each of the selected individual data sets for making the functional results comparable to one another before being integrated through functional meta-analysis. The individual transcriptomic analysis consisted of three consecutive steps run in R software  and applied separately to compare cases versus controls within samples from the same study to avoid variability among sample cohorts related to different uterine disorders. The same preprocessing of raw gene expression data, differential expression analysis, and functional enrichment analysis was performed in a sample cohort comparing cases versus controls ( Supplemental Fig. 1A , available online). The preprocessing step was performed using the affy v.1.52.0  R package for studies using Affymetrix platforms to measure gene expression and thelimma v.3.34.5 1262 VOL. 113 NO. 6 / JUNE 2020 ORIGINAL ARTICLE: GENETICS   R package for the remaining platforms. Normalization between samples was done using quantile normalization (limma R package) . Annotation from probe set to gene symbol was implemented with the biomaRt R package v.2.30.0. Annotation from probe set to gene symbol was implemented with the biomaRt R package v.2.30.0 . Next, exploratory analyses were performed to detect outliers and batch effects. The effect of the cycle phase of endometrial biopsy collection on the data was removed using linear models (limma v.3.34.5) as previously described elsewhere  because the samples were collected throughout the menstrual cycle . This correction ensures that the functional alterations obtained are due to the uterine disorder instead of the different proportions of cell types (stromal, epithelial) and/or the distinct menstrual cycle stages in which the endometrial biopsy samples were obtained . Differential expression analyses were applied using the limma R package  and functional enrichment analyses were executed using the gene set enrichment analysis (GSEA) logistic model implemented in themdgsa R package . TheP values for each function were calculated and corrected for false discovery rate (FDR). TheP values for each function were calculated and corrected for false discovery rate (FDR) . Two functional databases were consulted: the Kyoto Encyclopedia of Genes and Genomes (KEGG)  (release 81.0/2017-1-1) and Gene Ontology (GO)  (Release 1.2/2017-03-31). Functional Integration A functional meta-analysis using mdgsa  and metafor , R packages  was applied for each gene function evaluated, integrating each function among the different patient cohorts belonging to the same disorder (see Supplemental Fig. 1A). This methodology robustly highlights the common alterations across a set of studies, thus discarding those alterations that are exclusive of each individual study’s characteristics . In addition, it increases the statistical power through the integration of a higher number of samples and overcomes the limitations of individual studies’ heterogeneity regarding their distinct clinical population characteristics and experimental procedures. All integrations were performed under the DerSimonian and Laird  random effects model to account for individual study heterogeneity in the R environment . This model weighs the functional results of each study according to their inherent variability measured by the standard deviation (SD) of the logarithm of odds ratio (LOR) obtained in the GSEA analysis for each evaluated function. Consequently, studies with less variability are weighted more in the computation of thefinal meta-analysis results than those with high variability. Thus, meta-analysis highlights the most robust endometrial functions associated with each uterine disorder. A total of 6,390 functions (226 KEGG pathways, 4,405 GO biological processes (BP) terms, 1,093 GO molecular functions (MF) terms, and 666 GO cellular components (CC) terms) were evaluated through meta-analysis for each uterine disorder.P values were corrected for multiple testing by FDR , and functions were considered statistically signi ficant in the meta-analysis when FDR<0.05. The P values, summary LOR, and 95% confidence interval (CI) were calculated for all functions evaluated in the metaanalysis. To ensure unbiased results, funnel plots were analyzed for each function evaluated in the meta-analysis. The standard error (SE) of the individual LOR for each integrated study was calculated as an accuracy measure of the study performance. The LOR represents the effect size of the function associated with each uterine disorder compared with controls. If study heterogeneity and publication bias did not affect the functional meta-analysis, the individual LOR of all the integrated studies will be inside the 95% CI area of the funnel plot .\n"
     ]
    }
   ],
   "source": [
    "mynumb=10\n",
    "\n",
    "print(info_splitted_evaluation[mynumb])\n",
    "\n",
    "for d in info_splitted_evaluation:\n",
    "    \n",
    "    if d['Reference'] == info_splitted_evaluation[mynumb]['Reference'] and d['parent'] ==  info_splitted_evaluation[mynumb]['parent']:\n",
    "\n",
    "        print(d)\n",
    "\n",
    "        if d['chunk_index'] == 0:\n",
    "            info = d['content']\n",
    "        else:\n",
    "            info+=d['content'].split(\":\\n \")[-1]\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e93f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(piece_of_paper, all_papers):\n",
    "\n",
    "    for d in all_papers:\n",
    "    \n",
    "        if d['Reference'] == piece_of_paper['Reference'] and d['parent'] ==  piece_of_paper['parent']:\n",
    "\n",
    "            if d['chunk_index'] == 0:\n",
    "                info = d['content']\n",
    "            else:\n",
    "                info+=d['content'].split(\":\\n \")[-1]\n",
    "\n",
    "    return(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ed9c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [48:13<00:00,  4.82s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 600\n",
    "examples = []\n",
    "for sample in tqdm(random.sample(info_splitted_evaluation,N), total=N):\n",
    "    context = get_context(piece_of_paper=sample, all_papers=info_splitted_evaluation)\n",
    "    response = call_llm(llm=llm,prompt=QA_generation_prompt.format(context=context))\n",
    "    \n",
    "    try:\n",
    "        question = response.split(\"Question:\")[-1].split(\"Answer: \")[0].strip()\n",
    "        answer = response.split(\"Answer: \")[-1].strip()\n",
    "        examples.append({\n",
    "            \"context\" : context,\n",
    "            \"question\" : question,\n",
    "            \"answer\" : answer\n",
    "        })\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "with open(\"examples_evaluation_gemini_2-5.pkl\",\"wb\") as f:\n",
    "    pkl.dump(examples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1d753",
   "metadata": {},
   "source": [
    "## Evaluation of questions generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe8cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_groundedness_critique_prompt = \"\"\"\n",
    "You will be given a context and a question.\n",
    "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here are the question and context.\n",
    "\n",
    "Question: {question}\\n\n",
    "Context: {context}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_relevance_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how useful this question can be to researchers in the reproductive medicine field.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_standalone_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how context-independent this question is.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n",
    "For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n",
    "The questions can contain obscure technical nouns or acronyms like Gradio, Hub, Hugging Face or Space and still be a 5: it must simply be clear to an operator with access to documentation what the question is about.\n",
    "\n",
    "For instance, \"What is the name of the checkpoint from which the ViT model is imported?\" should receive a 1, since there is an implicit mention of a context, thus the question is not independent from the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d199ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating critique for each QA couple...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [56:53<00:00,  5.69s/it]  \n"
     ]
    }
   ],
   "source": [
    "print(\"Generating critique for each QA couple...\")\n",
    "for output in tqdm(examples,total=len(examples)):\n",
    "\n",
    "    evaluations = {\n",
    "        \"groundedness\": call_llm(\n",
    "            llm,\n",
    "            question_groundedness_critique_prompt.format(context=output[\"context\"], question=output[\"question\"]),\n",
    "        ),\n",
    "        \"relevance\": call_llm(\n",
    "            llm,\n",
    "            question_relevance_critique_prompt.format(question=output[\"question\"]),\n",
    "        ),\n",
    "        \"standalone\": call_llm(\n",
    "            llm,\n",
    "            question_standalone_critique_prompt.format(question=output[\"question\"]),\n",
    "        ),\n",
    "    }\n",
    "    try:\n",
    "        for criterion, evaluation in evaluations.items():\n",
    "            score, eval = (\n",
    "                int(evaluation.split(\"Total rating: \")[-1].strip()),\n",
    "                evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1],\n",
    "            )\n",
    "            output.update(\n",
    "                {\n",
    "                    f\"{criterion}_score\": score,\n",
    "                    f\"{criterion}_eval\": eval,\n",
    "                }\n",
    "            )\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a312109",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_questions = pd.DataFrame.from_dict(examples)\n",
    "generated_questions.loc[:,[\"question\",\"context\",\"answer\",\"groundedness_score\",\"relevance_score\",\"standalone_score\"]]\n",
    "with open(\"generated_questions_gemini_2-5.pkl\",\"wb\") as f:\n",
    "    pkl.dump(generated_questions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a98086",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_questions_final = generated_questions.loc[\n",
    "    (generated_questions[\"groundedness_score\"] >= 4)\n",
    "    & (generated_questions[\"relevance_score\"] >= 4)\n",
    "    & (generated_questions[\"standalone_score\"] >= 4)\n",
    "]\n",
    "with open(\"generated_questions_final_gemini_2-5.pkl\",\"wb\") as f:\n",
    "    pkl.dump(generated_questions_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7651e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generated_questions_final_gemini_2-5.pkl\",\"rb\") as f:\n",
    "    generated_questions_final = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15684535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>groundedness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>standalone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does the FGB rs1800790A allele affect fibr...</td>\n",
       "      <td>In F13A 34Val/Val wildtypes, carriage of the F...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>For which patient group might the ERA test be ...</td>\n",
       "      <td>The ERA test may be helpful for women with sus...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What kind of values does the Color Pathway too...</td>\n",
       "      <td>The Color Pathway tool accepts numerical values.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What is the implantation potential of an euplo...</td>\n",
       "      <td>Once an euploid blastocyst is identified, its ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What does the PRISMA 2020 statement reflect?</td>\n",
       "      <td>The PRISMA 2020 statement reflects advances in...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Which genes share genetic susceptibility for A...</td>\n",
       "      <td>The ESR1, HK3, and BRSK1 genes share genetic s...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>What database were the GSE26787 and GSE63901 d...</td>\n",
       "      <td>The Gene Expression Omnibus (GEO) database.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>What percentage of women globally are affected...</td>\n",
       "      <td>3.7% of women globally.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>What is the purpose of unique molecular identi...</td>\n",
       "      <td>Unique molecular identifiers are applied to ov...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>What are pinopodes?</td>\n",
       "      <td>Pinopodes are apical protrusions on the epithe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "6    How does the FGB rs1800790A allele affect fibr...   \n",
       "20   For which patient group might the ERA test be ...   \n",
       "25   What kind of values does the Color Pathway too...   \n",
       "32   What is the implantation potential of an euplo...   \n",
       "38        What does the PRISMA 2020 statement reflect?   \n",
       "..                                                 ...   \n",
       "566  Which genes share genetic susceptibility for A...   \n",
       "573  What database were the GSE26787 and GSE63901 d...   \n",
       "576  What percentage of women globally are affected...   \n",
       "589  What is the purpose of unique molecular identi...   \n",
       "596                                What are pinopodes?   \n",
       "\n",
       "                                                answer  groundedness_score  \\\n",
       "6    In F13A 34Val/Val wildtypes, carriage of the F...                 5.0   \n",
       "20   The ERA test may be helpful for women with sus...                 5.0   \n",
       "25    The Color Pathway tool accepts numerical values.                 5.0   \n",
       "32   Once an euploid blastocyst is identified, its ...                 5.0   \n",
       "38   The PRISMA 2020 statement reflects advances in...                 5.0   \n",
       "..                                                 ...                 ...   \n",
       "566  The ESR1, HK3, and BRSK1 genes share genetic s...                 5.0   \n",
       "573        The Gene Expression Omnibus (GEO) database.                 5.0   \n",
       "576                            3.7% of women globally.                 5.0   \n",
       "589  Unique molecular identifiers are applied to ov...                 5.0   \n",
       "596  Pinopodes are apical protrusions on the epithe...                 5.0   \n",
       "\n",
       "     relevance_score  standalone_score  \n",
       "6                5.0               5.0  \n",
       "20               5.0               5.0  \n",
       "25               4.0               5.0  \n",
       "32               5.0               5.0  \n",
       "38               5.0               5.0  \n",
       "..               ...               ...  \n",
       "566              5.0               5.0  \n",
       "573              4.0               5.0  \n",
       "576              5.0               5.0  \n",
       "589              5.0               5.0  \n",
       "596              4.0               5.0  \n",
       "\n",
       "[70 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_questions_final.loc[:,[\"question\",\"answer\",\"groundedness_score\",\"relevance_score\",\"standalone_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69babbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = generated_questions_final.to_dict(\"records\")\n",
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d2a80",
   "metadata": {},
   "source": [
    "### Create a function to check RAG performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c5ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(\n",
    "    documents,\n",
    "    chunk_size: int,\n",
    "    embedding_model\n",
    "):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_size//10,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]  # smart splitting\n",
    "    )\n",
    "\n",
    "    info_splitted = []\n",
    "\n",
    "    for j in documents:\n",
    "\n",
    "        for key, value in j.items():\n",
    "        \n",
    "            if key in ['Abstract', 'Introduction', 'Methods', 'Results', 'Discussion', 'Conclusion',] and value:\n",
    "\n",
    "                if len(value) > 1200:\n",
    "                    chunks = splitter.split_text(value)\n",
    "\n",
    "                    for i, c in enumerate(chunks):\n",
    "\n",
    "                        info_splitted.append(\n",
    "                            {\n",
    "                                \"chunk_index\":i,\n",
    "                                \"content\": j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")+\", DOI:\"+j.get(\"DOI\")+\"\\n\"+c,\n",
    "                                \"parent\":key,\n",
    "                                \"split\":True,\n",
    "                                \"DOI\":j.get(\"DOI\"),\n",
    "                                \"Reference\": j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")\n",
    "                            }\n",
    "                        )\n",
    "                else:\n",
    "\n",
    "                    info_splitted.append(\n",
    "                            {\n",
    "                                \"chunk_index\":0,\n",
    "                                \"content\":j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")+\", DOI:\"+j.get(\"DOI\")+\"\\n\"+value,\n",
    "                                \"parent\":key,\n",
    "                                \"split\":False,\n",
    "                                \"DOI\":j.get(\"DOI\"),\n",
    "                                \"Reference\": j.get('Authors').split(\",\")[0]+\" et al.,\"+j.get('Publication',\"Not identified\")\n",
    "                            }\n",
    "                        )\n",
    "    \n",
    "    texts = [chunk[\"content\"] for chunk in info_splitted]\n",
    "    metadatas = [{\"parent\": chunk[\"parent\"], \"chunk_index\": chunk[\"chunk_index\"],\"DOI\": chunk[\"DOI\"], \"Reference\": chunk[\"Reference\"]} for chunk in info_splitted]\n",
    "    ids = [str(uuid.uuid1()) for _ in metadatas]\n",
    "\n",
    "    db = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embedding_model,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    ")\n",
    "\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064d4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "<|system|>\n",
    "Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
    "<|user|>\n",
    "Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e054c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doi_links(text):\n",
    "    \"\"\"\n",
    "    Replace problematic Unicode dashes (like non-breaking hyphen) with normal ASCII dashes.\n",
    "    \"\"\"\n",
    "    return re.sub(r\"[\\u2010-\\u2015\\u2212]\", \"-\", text)\n",
    "\n",
    "def retrieve_context(question, k, database):\n",
    "    results = database.similarity_search(question, k)\n",
    "    selected_index = []\n",
    "    ideal_chunks = []\n",
    "    meta_selected = []\n",
    "\n",
    "    def is_new_chunk(r, selected_index):\n",
    "        next_chunk = \"_\".join([r[\"parent\"], r[\"Reference\"], str(r[\"chunk_index\"] + 1)])\n",
    "        prev_chunk = \"_\".join([r[\"parent\"], r[\"Reference\"], str(r[\"chunk_index\"] - 1)])\n",
    "        return next_chunk not in selected_index and prev_chunk not in selected_index\n",
    "\n",
    "    for doc in results:\n",
    "        r = doc.metadata\n",
    "\n",
    "        if r[\"parent\"] not in [\"Journal\", \"DOI\"] and is_new_chunk(r, selected_index):\n",
    "            ii = \"_\".join([r[\"parent\"], r[\"Reference\"], str(r[\"chunk_index\"])])\n",
    "            selected_index.append(ii)\n",
    "\n",
    "            candidates = database.get(\n",
    "                where={\"$and\": [{\"Reference\": r[\"Reference\"]}, {\"parent\": r[\"parent\"]}]}\n",
    "            )\n",
    "\n",
    "            max_index = len(candidates[\"metadatas\"]) - 1\n",
    "\n",
    "            meta_selected.append(candidates[\"metadatas\"])\n",
    "            ideal_chunks.append(\n",
    "                [\n",
    "                    doc\n",
    "                    for doc, meta in zip(\n",
    "                        candidates[\"documents\"], candidates[\"metadatas\"]\n",
    "                    )\n",
    "                    if meta[\"chunk_index\"]\n",
    "                    in [\n",
    "                        r[\"chunk_index\"],\n",
    "                        max(r[\"chunk_index\"] - 1, 0),\n",
    "                        min(r[\"chunk_index\"] + 1, max_index),\n",
    "                    ]\n",
    "                ]\n",
    "                )\n",
    "\n",
    "        context = []\n",
    "        for text, meta in zip(ideal_chunks, meta_selected):\n",
    "            if meta:  # Only proceed if meta is not empty\n",
    "                doi = (\n",
    "                    clean_doi_links(meta[0][\"DOI\"])\n",
    "                    if \"DOI\" in meta[0]\n",
    "                    else \"DOI not available\"\n",
    "                )\n",
    "                context.append(\n",
    "                    f\"Summary:\\n\\n{''.join(text)}\\n\\n\"\n",
    "                )\n",
    "\n",
    "    return(context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff0a7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    llm,\n",
    "    database,\n",
    "    num_docs_final=7,\n",
    "    recursive_chunk = False\n",
    "):\n",
    "    \"\"\"Answer a question using RAG with the given knowledge index.\"\"\"\n",
    "    # Gather documents with retriever\n",
    "    \n",
    "    if  recursive_chunk:\n",
    "        relevant_docs = retrieve_context(question=question, database=database,k=num_docs_final)\n",
    "    else:\n",
    "        relevant_docs = database.similarity_search(query=question, k=num_docs_final)\n",
    "        relevant_docs = [doc.page_content for doc in relevant_docs]  # keep only the text\n",
    "    \n",
    "\n",
    "    # Build the final prompt\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)])\n",
    "\n",
    "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
    "\n",
    "    # Redact an answer\n",
    "    answer = llm.invoke(final_prompt)\n",
    "\n",
    "    return answer.content, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d66498c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_tests(\n",
    "    eval_dataset,\n",
    "    llm,\n",
    "    database,\n",
    "    output_file,\n",
    "    recursive_chunk,\n",
    "    verbose=False,\n",
    "    test_settings = None,\n",
    "    num_docs_final = 7 # To document the test settings used\n",
    "):\n",
    "    \"\"\"Runs RAG tests on the given dataset and saves the results to the given output file.\"\"\"\n",
    "    try:  # load previous generations if they exist\n",
    "        with open(output_file, \"r\") as f:\n",
    "            outputs = json.load(f)\n",
    "    except:\n",
    "        outputs = []\n",
    "\n",
    "    for example in tqdm(eval_dataset):\n",
    "        question = example[\"question\"]\n",
    "        if question in [output[\"question\"] for output in outputs]:\n",
    "            continue\n",
    "            \n",
    "        answer, relevant_docs = answer_with_rag(question=question,llm=llm, database=database,recursive_chunk=recursive_chunk,num_docs_final=num_docs_final)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=======================================================\")\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {answer}\")\n",
    "            print(f'True answer: {example[\"answer\"]}')\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"true_answer\": example[\"answer\"],\n",
    "            \"generated_answer\": answer,\n",
    "            \"retrieved_docs\": [doc for doc in relevant_docs],\n",
    "        }\n",
    "        if test_settings:\n",
    "            result[\"test_settings\"] = test_settings\n",
    "        outputs.append(result)\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5f5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "EVALUATION_PROMPT = \"\"\"###Task Description:\n",
    "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
    "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
    "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
    "3. The output format MUST look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n",
    "4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output, it is required.\n",
    "\n",
    "###The instruction to evaluate:\n",
    "{instruction}\n",
    "\n",
    "###Response to evaluate:\n",
    "{response}\n",
    "\n",
    "###Reference Answer (Score 5):\n",
    "{reference_answer}\n",
    "\n",
    "###Score Rubrics:\n",
    "[Is the response correct, accurate, and factual based on the reference answer?]\n",
    "Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
    "Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
    "Score 3: The response is somewhat correct, accurate, and/or factual.\n",
    "Score 4: The response is mostly correct, accurate, and factual.\n",
    "Score 5: The response is completely correct, accurate, and factual.\n",
    "\n",
    "###Feedback:\"\"\"\n",
    "\n",
    "evaluation_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a fair evaluator language model.\"),\n",
    "        HumanMessagePromptTemplate.from_template(EVALUATION_PROMPT),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ca2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answers(\n",
    "    answer_path: str,\n",
    "    eval_chat_model,\n",
    "    evaluator_name: str,\n",
    "    evaluation_prompt_template: ChatPromptTemplate,\n",
    ") -> None:\n",
    "    \"\"\"Evaluates generated answers. Modifies the given answer file in place for better checkpointing.\"\"\"\n",
    "    answers = []\n",
    "    if os.path.isfile(answer_path):  # load previous generations if they exist\n",
    "        answers = json.load(open(answer_path, \"r\"))\n",
    "\n",
    "    for experiment in tqdm(answers):\n",
    "        if f\"eval_score_{evaluator_name}\" in experiment:\n",
    "            continue\n",
    "\n",
    "        eval_prompt = evaluation_prompt_template.format_messages(\n",
    "            instruction=experiment[\"question\"],\n",
    "            response=experiment[\"generated_answer\"],\n",
    "            reference_answer=experiment[\"true_answer\"],\n",
    "        )\n",
    "        \n",
    "        eval_result = eval_chat_model.invoke(eval_prompt)\n",
    "        feedback, score = [item.strip() for item in eval_result.content.split(\"[RESULT]\")]\n",
    "        experiment[f\"eval_score_{evaluator_name}\"] = score\n",
    "        experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n",
    "\n",
    "        with open(answer_path, \"w\") as f:\n",
    "            json.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e159aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./output\"):\n",
    "    os.mkdir(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function2 = HuggingFaceEmbeddings(model_name=\"avsolatorio/GIST-small-Embedding-v0\") # model_kwargs={'device': 'cuda'}\n",
    "# embedding_function2 = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-s\")\n",
    "# embedding_function2 = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")  #intfloat/e5-small-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b312c9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "The file already exists\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_4:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_5:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_6:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_7:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_8:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_9:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_10:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_4:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 193668.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 830947.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_9:\n",
      "Loading knowledge base embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 198245.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 828342.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_10:\n",
      "Loading knowledge base embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 199864.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 1048576.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_4:\n",
      "Loading knowledge base embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 178156.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 866364.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_5:\n",
      "Loading knowledge base embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 198245.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 889700.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_6:\n",
      "Loading knowledge base embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 202623.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 828342.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_7:\n",
      "Loading knowledge base embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 56/70 [01:18<00:19,  1.40s/it]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Database error: error returned from database: (code: 1) no such table: collections",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m db \u001b[38;5;241m=\u001b[39m load_embeddings(\n\u001b[1;32m     24\u001b[0m     info_articles_final,\n\u001b[1;32m     25\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[1;32m     26\u001b[0m     embedding_model\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning RAG...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mrun_rag_tests\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_reader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecursive_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_docs_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m evaluate_answers(\n\u001b[1;32m     43\u001b[0m     output_file_name,\n\u001b[1;32m     44\u001b[0m     llm_reader,\n\u001b[1;32m     45\u001b[0m     llm_model,\n\u001b[1;32m     46\u001b[0m     evaluation_prompt_template,\n\u001b[1;32m     47\u001b[0m )\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36mrun_rag_tests\u001b[0;34m(eval_dataset, llm, database, output_file, recursive_chunk, verbose, test_settings, num_docs_final)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m [output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m answer, relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[43manswer_with_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrecursive_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_docs_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_docs_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=======================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m, in \u001b[0;36manswer_with_rag\u001b[0;34m(question, llm, database, num_docs_final, recursive_chunk)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Gather documents with retriever\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m  recursive_chunk:\n\u001b[0;32m---> 12\u001b[0m     relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_docs_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     relevant_docs \u001b[38;5;241m=\u001b[39m database\u001b[38;5;241m.\u001b[39msimilarity_search(query\u001b[38;5;241m=\u001b[39mquestion, k\u001b[38;5;241m=\u001b[39mnum_docs_final)\n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m, in \u001b[0;36mretrieve_context\u001b[0;34m(question, k, database)\u001b[0m\n\u001b[1;32m     22\u001b[0m ii \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m\"\u001b[39m], r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mstr\u001b[39m(r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_index\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n\u001b[1;32m     23\u001b[0m selected_index\u001b[38;5;241m.\u001b[39mappend(ii)\n\u001b[0;32m---> 25\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$and\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReference\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReference\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m max_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(candidates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m meta_selected\u001b[38;5;241m.\u001b[39mappend(candidates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:700\u001b[0m, in \u001b[0;36mChroma.get\u001b[0;34m(self, ids, where, limit, offset, where_document, include)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m include\n\u001b[0;32m--> 700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/chromadb/api/models/Collection.py:131\u001b[0m, in \u001b[0;36mCollection.get\u001b[0;34m(self, ids, where, limit, offset, where_document, include)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get embeddings and their associate data from the data store. If no ids or where filter is provided returns\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03mall embeddings up to limit starting at offset.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m get_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_get_request(\n\u001b[1;32m    125\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    126\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[1;32m    127\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[1;32m    128\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    129\u001b[0m )\n\u001b[0;32m--> 131\u001b[0m get_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_get_response(\n\u001b[1;32m    144\u001b[0m     response\u001b[38;5;241m=\u001b[39mget_results, include\u001b[38;5;241m=\u001b[39mget_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    145\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/chromadb/api/rust.py:354\u001b[0m, in \u001b[0;36mRustBindingsAPI._get\u001b[0;34m(self, collection_id, ids, where, sort, limit, offset, page, page_size, where_document, include, tenant, database)\u001b[0m\n\u001b[1;32m    342\u001b[0m ids_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_telemetry_client\u001b[38;5;241m.\u001b[39mcapture(\n\u001b[1;32m    344\u001b[0m     CollectionGetEvent(\n\u001b[1;32m    345\u001b[0m         collection_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[1;32m    352\u001b[0m )\n\u001b[0;32m--> 354\u001b[0m rust_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GetResult(\n\u001b[1;32m    367\u001b[0m     ids\u001b[38;5;241m=\u001b[39mrust_response\u001b[38;5;241m.\u001b[39mids,\n\u001b[1;32m    368\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39mrust_response\u001b[38;5;241m.\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mrust_response\u001b[38;5;241m.\u001b[39mmetadatas,\n\u001b[1;32m    374\u001b[0m )\n",
      "\u001b[0;31mInternalError\u001b[0m: Database error: error returned from database: (code: 1) no such table: collections"
     ]
    }
   ],
   "source": [
    "for chunk_size in [1000,1250,1500,1750,2000]:  # Add other chunk sizes (in tokens) as needed\n",
    "\n",
    "    for llm_model in [\"gemini-2.0-flash\",\"gemma-3-27b-it\"]:\n",
    "\n",
    "        llm_reader = init_chat_model(llm_model, model_provider=\"google_genai\",temperature=0.5,max_output_tokens=1024)\n",
    "\n",
    "        for embedding_model in [\"avsolatorio/GIST-small-Embedding-v0\",\"Snowflake/snowflake-arctic-embed-s\",\"intfloat/e5-small-v2\"]:\n",
    "\n",
    "            name_model = embedding_model.split(\"/\")[1]\n",
    "            embedding_function = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "\n",
    "            for recursive_chunk in [False, True]:\n",
    "\n",
    "                for k in range(4,11):\n",
    "            \n",
    "                    settings_name = f\"chunk_{chunk_size}_reader-model_{llm_model}_emnedding_model_{name_model}recursive_{recursive_chunk}_k_{k}\"\n",
    "                    output_file_name = f\"./output/rag_{settings_name}.json\"\n",
    "\n",
    "                    print(f\"Running evaluation for {settings_name}:\")\n",
    "\n",
    "                    print(\"Loading knowledge base embeddings...\")\n",
    "\n",
    "                    db = load_embeddings(\n",
    "                        info_articles_final,\n",
    "                        chunk_size=chunk_size,\n",
    "                        embedding_model=embedding_function,\n",
    "                    )\n",
    "\n",
    "                    print(\"Running RAG...\")\n",
    "                    run_rag_tests(\n",
    "                        eval_dataset=eval_dataset,\n",
    "                        llm=llm_reader,\n",
    "                        database=db,\n",
    "                        output_file=output_file_name,\n",
    "                        verbose=False,\n",
    "                        test_settings=settings_name,\n",
    "                        recursive_chunk=recursive_chunk,\n",
    "                        num_docs_final=k\n",
    "                    )\n",
    "\n",
    "                    print(\"Running evaluation...\")\n",
    "                    evaluate_answers(\n",
    "                        output_file_name,\n",
    "                        llm_reader,\n",
    "                        llm_model,\n",
    "                        evaluation_prompt_template,\n",
    "                    )\n",
    "                    print(\"Removing database\")\n",
    "                    db.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f523874a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Error getting collection: Database error: error returned from database: (code: 1) no such table: collections",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEndometrium\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:350\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    335\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:440\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 440\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__query_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/langchain_core/utils/utils.py:54\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:157\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[0;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/chromadb/api/models/Collection.py:219\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m query_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_query_request(\n\u001b[1;32m    209\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[1;32m    210\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    217\u001b[0m )\n\u001b[0;32m--> 219\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_query_response(\n\u001b[1;32m    231\u001b[0m     response\u001b[38;5;241m=\u001b[39mquery_results, include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    232\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/RAG/lib/python3.9/site-packages/chromadb/api/rust.py:493\u001b[0m, in \u001b[0;36mRustBindingsAPI._query\u001b[0;34m(self, collection_id, query_embeddings, n_results, where, where_document, include, tenant, database)\u001b[0m\n\u001b[1;32m    478\u001b[0m query_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(query_embeddings)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_telemetry_client\u001b[38;5;241m.\u001b[39mcapture(\n\u001b[1;32m    480\u001b[0m     CollectionQueryEvent(\n\u001b[1;32m    481\u001b[0m         collection_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m )\n\u001b[0;32m--> 493\u001b[0m rust_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\n\u001b[1;32m    505\u001b[0m     ids\u001b[38;5;241m=\u001b[39mrust_response\u001b[38;5;241m.\u001b[39mids,\n\u001b[1;32m    506\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39mrust_response\u001b[38;5;241m.\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     distances\u001b[38;5;241m=\u001b[39mrust_response\u001b[38;5;241m.\u001b[39mdistances,\n\u001b[1;32m    513\u001b[0m )\n",
      "\u001b[0;31mInternalError\u001b[0m: Error getting collection: Database error: error returned from database: (code: 1) no such table: collections"
     ]
    }
   ],
   "source": [
    "db.similarity_search(\"Endometrium\",k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f6b57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "outputs = []\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    output = pd.DataFrame(json.load(open(file, \"r\")))\n",
    "    output[\"settings\"] = file\n",
    "    outputs.append(output)\n",
    "result = pd.concat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53ccea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_5:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:39<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_6:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_7:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_8:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:42<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_9:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:44<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_10:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:45<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:38<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_4:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:33<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_5:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_6:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:35<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_7:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_8:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:39<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_9:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:36<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_10:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_4:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_5:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:09<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_6:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_7:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_8:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:42<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_9:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:41<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:43<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_10:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:44<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_4:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:34<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_5:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:37<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_6:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:37<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_7:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:37<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_8:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_9:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:39<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_10:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_4:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:37<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_5:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:37<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_6:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:38<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_7:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:40<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_8:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:39<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:40<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_9:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:39<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n",
      "Running evaluation for chunk_2000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_10:\n",
      "Loading knowledge base embeddings...\n",
      "Running RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:42<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:42<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing database\n"
     ]
    }
   ],
   "source": [
    "for chunk_size in [1000,1500,2000]:  # Add other chunk sizes (in tokens) as needed\n",
    "\n",
    "    for llm_model in [\"gemini-2.0-flash\"]:\n",
    "\n",
    "        llm_reader = init_chat_model(llm_model, model_provider=\"google_genai\",temperature=0.5,max_output_tokens=1024)\n",
    "\n",
    "        for embedding_model in [\"avsolatorio/GIST-small-Embedding-v0\",\"Snowflake/snowflake-arctic-embed-s\",\"intfloat/e5-small-v2\"]:\n",
    "\n",
    "            name_model = embedding_model.split(\"/\")[1]\n",
    "            embedding_function = HuggingFaceEmbeddings(model_name=embedding_model, model_kwargs={'device': 'cuda'})\n",
    "\n",
    "            for recursive_chunk in [False, True]:\n",
    "\n",
    "                for k in range(4,11):\n",
    "            \n",
    "                    settings_name = f\"chunk_{chunk_size}_reader-model_{llm_model}_emnedding_model_{name_model}recursive_{recursive_chunk}_k_{k}\"\n",
    "                    output_file_name = f\"./output/rag_{settings_name}.json\"\n",
    "\n",
    "                    if os.path.exists(output_file_name):\n",
    "                        output = pd.DataFrame(json.load(open(output_file_name)))\n",
    "                        if f\"eval_score_{llm_model}\" in output.columns:\n",
    "                            print(\"The file already exists\")\n",
    "                            continue\n",
    "\n",
    "                    print(f\"Running evaluation for {settings_name}:\")\n",
    "\n",
    "                    print(\"Loading knowledge base embeddings...\")\n",
    "\n",
    "                    db = load_embeddings(\n",
    "                        info_articles_final,\n",
    "                        chunk_size=chunk_size,\n",
    "                        embedding_model=embedding_function,\n",
    "                    )\n",
    "\n",
    "                    print(\"Running RAG...\")\n",
    "                    run_rag_tests(\n",
    "                        eval_dataset=eval_dataset,\n",
    "                        llm=llm_reader,\n",
    "                        database=db,\n",
    "                        output_file=output_file_name,\n",
    "                        verbose=False,\n",
    "                        test_settings=settings_name,\n",
    "                        recursive_chunk=recursive_chunk,\n",
    "                        num_docs_final=k\n",
    "                    )\n",
    "\n",
    "                    print(\"Running evaluation...\")\n",
    "                    evaluate_answers(\n",
    "                        output_file_name,\n",
    "                        llm_reader,\n",
    "                        llm_model,\n",
    "                        evaluation_prompt_template,\n",
    "                    )\n",
    "                    print(\"Removing database\")\n",
    "                    db.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f6b57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "outputs = []\n",
    "for file in glob.glob(\"./output/*.json\"):\n",
    "    output = pd.DataFrame(json.load(open(file, \"r\")))\n",
    "    output[\"settings\"] = file\n",
    "    outputs.append(output)\n",
    "result = pd.concat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23117f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"eval_score_gemini-2.0-flash\"] = result[\"eval_score_gemini-2.0-flash\"].apply(lambda x: int(x) if isinstance(x, str) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d5ebaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"eval_score_gemini-2.0-flash\"] = result[\"eval_score_gemini-2.0-flash\"]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e8551da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "settings\n",
       "./output/rag_chunk_1000_reader-model_gemma-3-27b-it_emnedding_model_GIST-small-Embedding-v0recursive_False_k_4.json        0.000000\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_4.json     0.746032\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_10.json    0.793651\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_5.json     0.796825\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_6.json     0.806349\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_9.json     0.812698\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_7.json     0.815873\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_4.json      0.815873\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_5.json      0.822222\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_6.json      0.828571\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_False_k_8.json     0.831746\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_7.json      0.831746\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_9.json      0.831746\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_10.json     0.841270\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_4.json      0.844444\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_snowflake-arctic-embed-srecursive_True_k_8.json      0.847619\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_5.json      0.876190\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_6.json      0.882540\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_4.json       0.885714\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_7.json      0.898413\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_6.json       0.904762\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_5.json       0.907937\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_4.json                  0.923810\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_7.json                  0.923810\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_8.json       0.926984\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_7.json       0.926984\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_4.json                   0.939683\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_8.json      0.939683\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_10.json      0.942857\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_9.json      0.942857\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_True_k_9.json       0.949206\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_10.json                  0.955556\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_6.json                  0.955556\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_GIST-small-Embedding-v0recursive_False_k_10.json     0.958730\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_7.json                   0.961905\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_8.json                   0.965079\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_5.json                  0.968254\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_9.json                  0.968254\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_10.json                 0.971429\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_6.json                   0.971429\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_5.json                   0.971429\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_False_k_8.json                  0.974603\n",
       "./output/rag_chunk_1000_reader-model_gemini-2.0-flash_emnedding_model_e5-small-v2recursive_True_k_9.json                   0.974603\n",
       "Name: eval_score_gemini-2.0-flash, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_scores = result.groupby(\"settings\")[\"eval_score_gemini-2.0-flash\"].mean()\n",
    "average_scores.sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
